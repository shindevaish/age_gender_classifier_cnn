{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "574d1ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d863f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"0Q6A9930.JPG\")\n",
    "image = cv2.resize(image,(720,640))\n",
    "\n",
    "face_pbtxt=\"models/opencv_face_detector.pbtxt\"\n",
    "face_pb=\"models/opencv_face_detector_uint8.pb\"\n",
    "age_model=\"models/age_net.caffemodel\"\n",
    "age_prototxt=\"models/age_deploy.prototxt\"\n",
    "gender_prototxt=\"models/gender_deploy.prototxt\"\n",
    "gender_model=\"models/gender_net.caffemodel\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bed455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Models\n",
    "face=cv2.dnn.readNet(face_pb,face_pbtxt)\n",
    "age=cv2.dnn.readNet(age_model,age_prototxt)\n",
    "gender=cv2.dnn.readNet(gender_model,gender_prototxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b46ead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup Classifications\n",
    "age_classification=['(0-2)','(3-6)','(8-12)','(15-20)','(25-32)','(38-43)','(48-53)','(60-100)']\n",
    "gender_classification=['Male','Female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa30e734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blob shape: (1, 3, 300, 300)\n",
      "Detected faces shape: (1, 1, 200, 7)\n"
     ]
    }
   ],
   "source": [
    "#Image Copy\n",
    "img_cp=image.copy()\n",
    "\n",
    "img_height=img_cp.shape[0]\n",
    "img_width=img_cp.shape[1]\n",
    "blob = cv2.dnn.blobFromImage(img_cp,1.0,(300,300),[104,117,123],True,False)\n",
    "\n",
    "\n",
    "face.setInput(blob)\n",
    "detected_faces=face.forward()\n",
    "# print(f\"Confidence: {detected_faces[0,0]}\")\n",
    "\n",
    "print(\"Blob shape:\", blob.shape)\n",
    "print(\"Detected faces shape:\", detected_faces.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06dd0a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected Faces:  [0.         1.         0.9842712  0.48270634 0.26641303 0.6934413\n",
      " 0.43035346]\n",
      "Confidence: 0.984 | Face at: (347, 170) to (499, 275)\n"
     ]
    }
   ],
   "source": [
    "face_bounds=[]\n",
    "for i in range(detected_faces.shape[2]):\n",
    "    confidence=detected_faces[0,0,i,2]\n",
    "    if (confidence>0.9):\n",
    "        print(\"Detected Faces: \",detected_faces[0,0,i],)\n",
    "        x1=int(detected_faces[0,0,i,3]*img_width)\n",
    "        y1=int(detected_faces[0,0,i,4]*img_height)\n",
    "        x2=int(detected_faces[0,0,i,5]*img_width)\n",
    "        y2=int(detected_faces[0,0,i,6]*img_height)\n",
    "        # print([x1,y1,x2,y2])\n",
    "        cv2.rectangle(img_cp,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "        print(f\"Confidence: {confidence:.3f} | Face at: ({x1}, {y1}) to ({x2}, {y2})\")\n",
    "        face_bounds.append([x1,y1,x2,y2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41b80cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face_bounds:  [[347, 170, 499, 275]]\n",
      "Face [[ 75  76  80]\n",
      " [ 74  75  79]\n",
      " [ 82  83  87]\n",
      " [ 61  59  65]\n",
      " [ 87  87  93]\n",
      " [ 84  80  82]\n",
      " [ 82  76  81]\n",
      " [ 88  84  89]\n",
      " [ 89  86  88]\n",
      " [117 112 113]\n",
      " [ 92  86  87]\n",
      " [ 99  92  95]\n",
      " [ 99  96  98]\n",
      " [ 80  75  77]\n",
      " [113 106 109]\n",
      " [110 104 108]\n",
      " [ 74  70  69]\n",
      " [ 67  62  64]\n",
      " [ 97  95  95]\n",
      " [ 73  68  68]\n",
      " [ 88  86  86]\n",
      " [ 85  80  80]\n",
      " [ 69  64  63]\n",
      " [ 94  92  91]\n",
      " [ 95  91  93]\n",
      " [ 99  94  95]\n",
      " [ 96  94  93]\n",
      " [ 98  98  98]\n",
      " [ 54  49  50]\n",
      " [ 46  41  42]\n",
      " [ 70  65  67]\n",
      " [ 45  41  42]\n",
      " [ 78  74  74]\n",
      " [111 106 108]\n",
      " [ 87  85  87]\n",
      " [ 91  86  87]\n",
      " [ 89  83  85]\n",
      " [ 85  78  80]\n",
      " [103  96  99]\n",
      " [ 93  90  92]\n",
      " [ 83  78  79]\n",
      " [ 40  35  39]\n",
      " [ 85  83  83]\n",
      " [ 74  74  74]\n",
      " [ 20  20  20]\n",
      " [ 76  74  74]\n",
      " [ 90  87  89]\n",
      " [ 63  60  62]\n",
      " [ 95  95  96]\n",
      " [ 96  94  98]\n",
      " [ 90  89  91]\n",
      " [ 59  60  61]\n",
      " [ 58  57  59]\n",
      " [ 58  59  63]\n",
      " [ 41  39  43]\n",
      " [ 63  62  66]\n",
      " [ 48  47  53]\n",
      " [ 64  65  69]\n",
      " [ 97  97 103]\n",
      " [ 77  77  82]\n",
      " [ 76  78  83]\n",
      " [ 99 102 107]\n",
      " [ 84  87  92]\n",
      " [ 84  84  91]\n",
      " [ 79  80  84]\n",
      " [ 77  78  82]\n",
      " [101 102 112]\n",
      " [105 110 115]\n",
      " [123 123 129]\n",
      " [ 94  93 102]\n",
      " [ 84  86  94]\n",
      " [122 122 128]\n",
      " [ 96  99 104]\n",
      " [ 87  86  96]\n",
      " [ 80  77  87]\n",
      " [125 124 133]\n",
      " [135 137 147]\n",
      " [113 114 124]\n",
      " [ 92  97 101]\n",
      " [120 122 132]\n",
      " [ 90  92 102]\n",
      " [ 96  97 108]\n",
      " [108 110 118]\n",
      " [ 96  99 104]\n",
      " [110 112 122]\n",
      " [ 97 100 106]\n",
      " [127 134 141]\n",
      " [120 122 132]\n",
      " [122 120 126]\n",
      " [140 143 148]\n",
      " [ 79  79  87]\n",
      " [ 95  96 106]\n",
      " [ 82  84  89]\n",
      " [ 55  59  64]\n",
      " [ 49  49  55]\n",
      " [ 57  60  64]\n",
      " [ 62  65  71]\n",
      " [ 41  45  46]\n",
      " [ 36  34  41]\n",
      " [ 45  42  49]\n",
      " [ 77  79  83]\n",
      " [ 40  39  43]\n",
      " [ 33  29  35]\n",
      " [ 43  43  43]\n",
      " [ 28  27  29]\n",
      " [ 37  34  36]\n",
      " [ 36  33  35]\n",
      " [ 63  62  64]\n",
      " [ 40  41  41]\n",
      " [ 16  10  15]\n",
      " [ 57  55  57]\n",
      " [ 33  32  34]\n",
      " [ 36  36  36]\n",
      " [ 31  28  30]\n",
      " [ 35  36  40]\n",
      " [ 44  45  49]\n",
      " [ 23  22  24]\n",
      " [ 29  31  32]\n",
      " [ 29  30  34]\n",
      " [ 13  15  16]\n",
      " [ 23  25  26]\n",
      " [ 23  26  30]\n",
      " [ 28  29  33]\n",
      " [ 43  42  46]\n",
      " [ 35  36  38]\n",
      " [ 63  65  66]\n",
      " [ 33  34  38]\n",
      " [ 19  19  25]\n",
      " [ 44  46  47]\n",
      " [ 41  43  44]\n",
      " [ 55  54  56]\n",
      " [ 24  26  27]\n",
      " [ 24  23  25]\n",
      " [ 23  24  28]\n",
      " [ 40  43  47]\n",
      " [ 22  24  25]\n",
      " [ 33  37  38]\n",
      " [ 52  52  57]\n",
      " [ 35  36  38]\n",
      " [ 29  32  36]\n",
      " [ 37  40  45]\n",
      " [ 73  77  82]\n",
      " [ 45  49  58]\n",
      " [ 70  77  88]\n",
      " [ 58  60  68]\n",
      " [ 28  34  40]\n",
      " [ 23  25  35]\n",
      " [121 123 137]\n",
      " [ 93 105 117]\n",
      " [ 51  58  77]\n",
      " [ 81  87 102]\n",
      " [ 67  77  88]\n",
      " [ 71  81  92]\n",
      " [ 55  57  67]\n",
      " [ 67  74  77]\n",
      " [ 47  51  56]\n",
      " [ 31  34  38]\n",
      " [ 31  31  35]\n",
      " [ 41  42  46]\n",
      " [ 46  45  47]\n",
      " [ 96  97  98]\n",
      " [ 58  56  55]\n",
      " [ 27  25  25]\n",
      " [ 46  44  44]\n",
      " [ 43  38  40]\n",
      " [ 84  80  79]\n",
      " [ 64  59  60]\n",
      " [ 98  93  92]\n",
      " [ 99  97  95]\n",
      " [ 90  87  86]\n",
      " [ 60  55  54]\n",
      " [ 45  41  40]\n",
      " [ 53  48  49]\n",
      " [ 75  74  70]\n",
      " [ 62  58  57]\n",
      " [ 64  59  58]\n",
      " [ 57  50  47]\n",
      " [ 52  49  45]\n",
      " [ 48  44  43]\n",
      " [ 81  77  72]\n",
      " [ 76  71  68]\n",
      " [ 77  73  68]]\n",
      "Gender : Male\n",
      "AGE : (8-12)\n"
     ]
    }
   ],
   "source": [
    "print(\"face_bounds: \",face_bounds)\n",
    "\n",
    "for face_bound in face_bounds:\n",
    "    try:\n",
    "        face=img_cp[max(0,face_bound[1]-15): min(face_bound[3]+15,img_cp.shape[0]-1),\n",
    "                    max(0,face_bound[0]-15): min(face_bound[2]+15,img_cp.shape[1]-1)]\n",
    "        \n",
    "        print(\"Face\",face[0])\n",
    "    \n",
    "        blob= cv2.dnn.blobFromImage(face, 1.0, (227,227),[104,117,123],True)\n",
    "        gender.setInput(blob)\n",
    "        predicted_gender=gender.forward()\n",
    "        _gender= gender_classification[predicted_gender[0].argmax()]\n",
    "        print(\"Gender :\",_gender)\n",
    "\n",
    "        age.setInput(blob)\n",
    "        age_prediction=age.forward()\n",
    "        _age=age_classification[age_prediction[0].argmax()]\n",
    "        print(\"AGE :\",_age)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45acbadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    cv2.imshow(\"result\",img_cp)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934264f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
