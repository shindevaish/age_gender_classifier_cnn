{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "334b3f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.nn import MSELoss, CrossEntropyLoss\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import time\n",
    "\n",
    "from data_loader import FaceDataset\n",
    "from model import AgeGenderModel\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa7b26e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "t = torch.tensor([1,2], device=device)\n",
    "device\n",
    "t = t*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8354d43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e293b46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])  \n",
    "\n",
    "full_dataset = FaceDataset(root_dir='part1', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb27e9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_indices = [i for i, (data, label) in enumerate(full_dataset) if data is not None]\n",
    "dataset = torch.utils.data.Subset(full_dataset, filtered_indices)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e8de4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = 32, shuffle = True, num_workers = 4)\n",
    "val_loader = DataLoader(val_dataset, batch_size = 32, shuffle = False, num_workers = 4)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 32, shuffle = False, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d795cff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = [f for f in os.listdir('part1') if f.endswith(\".jpg\")]\n",
    "len(image_files)\n",
    "for i in image_files:\n",
    "    parts = i.split('_')\n",
    "    gender = int(parts[1])\n",
    "    if gender > 1:\n",
    "        print(gender, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a52e86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "tensor([0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
      "        0, 0, 0, 0, 0, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
      "        1, 0, 0, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "tensor([1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
      "        0, 0, 1, 0, 1, 1, 1, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "next(iter(train_loader))[1].shape\n",
    "next(iter(train_loader))[1][:, 1]\n",
    "z = 1\n",
    "for i, (images, labels) in enumerate(train_loader) :\n",
    "    images = images.to(device)\n",
    "    ages = labels[:, 0].to(device)\n",
    "    genders = labels[:, 1].long().to(device)\n",
    "    print(genders)\n",
    "    z += 1\n",
    "    if z > 5: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b911d71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "model = AgeGenderModel()\n",
    "print(next(model.parameters()).dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46aeb541",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = AgeGenderModel().to(device)\n",
    "\n",
    "age_criterion = MSELoss()\n",
    "gender_criterion = CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cce0bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 309.706742, Time: 17.55sec\n",
      "Epoch 2/20, Loss: 145.057676, Time: 17.38sec\n",
      "Epoch 3/20, Loss: 115.555329, Time: 17.42sec\n",
      "Epoch 4/20, Loss: 84.926439, Time: 17.67sec\n",
      "Epoch 5/20, Loss: 75.874583, Time: 17.59sec\n",
      "Epoch 6/20, Loss: 60.225246, Time: 17.64sec\n",
      "Epoch 7/20, Loss: 53.498460, Time: 17.51sec\n",
      "Epoch 8/20, Loss: 52.052705, Time: 17.52sec\n",
      "Epoch 9/20, Loss: 50.825881, Time: 17.54sec\n",
      "Epoch 10/20, Loss: 34.590564, Time: 17.65sec\n",
      "Epoch 11/20, Loss: 28.488644, Time: 17.62sec\n",
      "Epoch 12/20, Loss: 31.371851, Time: 17.58sec\n",
      "Epoch 13/20, Loss: 20.677656, Time: 17.63sec\n",
      "Epoch 14/20, Loss: 15.551998, Time: 17.70sec\n",
      "Epoch 15/20, Loss: 13.550428, Time: 17.61sec\n",
      "Epoch 16/20, Loss: 10.885607, Time: 17.62sec\n",
      "Epoch 17/20, Loss: 10.209280, Time: 17.89sec\n",
      "Epoch 18/20, Loss: 8.080401, Time: 17.85sec\n",
      "Epoch 19/20, Loss: 10.020575, Time: 17.59sec\n",
      "Epoch 20/20, Loss: 10.109992, Time: 17.55sec\n",
      "Training complete. Model saved.\n"
     ]
    }
   ],
   "source": [
    "num_gender_classes = 2\n",
    "\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader) :\n",
    "        images = images.to(device)\n",
    "        ages = labels[:, 0].to(device)\n",
    "        genders = labels[:, 1].long().to(device)\n",
    "        max_gender = genders.max().item()\n",
    "        if max_gender >= num_gender_classes:\n",
    "            print(i, genders)\n",
    "            print(f\"Error in batch {i} Epoch {epoch+1}\")\n",
    "            print(f\"Maximun gender value {max_gender}\")\n",
    "            break\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        age_pred, gender_pred = model(images)\n",
    "\n",
    "        age_loss = age_criterion(age_pred.squeeze(), ages)\n",
    "        gender_loss = gender_criterion(gender_pred, genders)\n",
    "        total_loss = age_loss + gender_loss\n",
    "\n",
    "        total_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += total_loss.item()\n",
    "    end_time = time.time()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):4f}, Time: {end_time - start_time:.2f}sec\")\n",
    "\n",
    "torch.save(model.state_dict(),'models/age_gender_model.pth')\n",
    "print(\"Training complete. Model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff7a5593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "from data_loader import FaceDataset\n",
    "from model import AgeGenderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e01eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a89ae0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'age_gender_model.path'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Load the trained model\u001b[39;00m\n\u001b[32m      5\u001b[39m model = AgeGenderModel().to(device)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m model.load_state_dict(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mage_gender_model.path\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m      7\u001b[39m model.eval()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/agdenv/lib/python3.11/site-packages/torch/serialization.py:998\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m    995\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m    996\u001b[39m     pickle_load_args[\u001b[33m'\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m'\u001b[39m] = \u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m998\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m    999\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1000\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1001\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1002\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1003\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/agdenv/lib/python3.11/site-packages/torch/serialization.py:445\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    443\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[32m    444\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    446\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    447\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/agdenv/lib/python3.11/site-packages/torch/serialization.py:426\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[32m--> \u001b[39m\u001b[32m426\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'age_gender_model.path'"
     ]
    }
   ],
   "source": [
    "root_dir = '/Users/vaishnavishinde/Desktop/age_detector/dataset'\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Load the trained model\n",
    "model = AgeGenderModel().to(device)\n",
    "model.load_state_dict(torch.load('age_gender_model.path'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecf2bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = UTKFaceDataset(root_dir=root_dir, transform=transform)\n",
    "filtered_indices = [i for i, (data, label) in enumerate(full_dataset) if data is not None]\n",
    "dataset = torch.utils.data.Subset(full_dataset, filtered_indices)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "_, _, test_dataset = random_split(dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59c8005",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def main():\n",
    "    root_dir = 'path/to/UTKFace'\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Load the trained model\n",
    "    model = AgeGenderModel().to(device)\n",
    "    model.load_state_dict(torch.load('age_gender_model.pth'))\n",
    "    model.eval()\n",
    "    \n",
    "    # Recreate the dataset split for a consistent test set\n",
    "    full_dataset = UTKFaceDataset(root_dir=root_dir, transform=get_transforms())\n",
    "    filtered_indices = [i for i, (data, label) in enumerate(full_dataset) if data is not None]\n",
    "    dataset = torch.utils.data.Subset(full_dataset, filtered_indices)\n",
    "    \n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = int(0.1 * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "    _, _, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "    \n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    all_ages = []\n",
    "    all_age_preds = []\n",
    "    all_genders = []\n",
    "    all_gender_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            ages = labels[:, 0].numpy()\n",
    "            genders = labels[:, 1].numpy()\n",
    "            \n",
    "            age_pred, gender_pred = model(images)\n",
    "            \n",
    "            all_ages.extend(ages)\n",
    "            all_genders.extend(genders)\n",
    "            all_age_preds.extend(age_pred.squeeze().cpu().numpy())\n",
    "            all_gender_preds.extend(torch.argmax(gender_pred, dim=1).cpu().numpy())\n",
    "\n",
    "    # Gender metrics\n",
    "    gender_accuracy = accuracy_score(all_genders, all_gender_preds)\n",
    "    conf_matrix = confusion_matrix(all_genders, all_gender_preds)\n",
    "\n",
    "    # Age metrics\n",
    "    mae = mean_absolute_error(all_ages, all_age_preds)\n",
    "    \n",
    "    print(f\"Gender Accuracy: {gender_accuracy:.4f}\")\n",
    "    print(\"Gender Confusion Matrix:\\n\", conf_matrix)\n",
    "    print(f\"Age Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agdenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
